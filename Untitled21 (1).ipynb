{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93bec001-eca9-4986-a5ee-fd2014c57f93",
   "metadata": {},
   "source": [
    "#### Assignment Code: DA-AG-016\n",
    "### KNN & PCA | Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8720484-2acc-408a-90a2-aed361be8c51",
   "metadata": {},
   "source": [
    "Question 1: What is K-Nearest Neighbors (KNN) and how does it work in both\n",
    "classification and regression problems?\n",
    "-\n",
    "K-Nearest Neighbors (KNN) is a supervised machine learning algorithm used for both classification and regression tasks. It is a non-parametric, instance-based learning method, meaning it makes predictions based on the training data directly without creating an explicit model.\n",
    "\n",
    "-> How KNN Works (General Idea)\n",
    "\n",
    " 1.Input: A data point you want to classify or predict (test data).\n",
    "\n",
    " 2.Distance Measurement: Compute the distance between the test point and all points in the training dataset using a metric (commonly Euclidean distance, but others like Manhattan or Minkowski are also used).\n",
    "\n",
    " 3.Find Neighbors: Identify the K closest points (neighbors) to the test point.\n",
    "\n",
    " 4.Make a Prediction:\n",
    " - Classification: Predict the class most common among the K neighbors.\n",
    " - Regression: Predict the average (or weighted average) of the values of the K neighbors.\n",
    "\n",
    "-> KNN for Classification\n",
    "\n",
    " - Example: You want to classify whether a fruit is an apple or orange.\n",
    "\n",
    " - Steps:\n",
    "   - Calculate the distance from the test fruit to all labeled fruits in the training set.\n",
    "   - Choose the K nearest (e.g., 5) labeled fruits.\n",
    "   - Count how many are apples vs. oranges.\n",
    "   - Assign the class with the majority vote.\n",
    "\n",
    "-> Works well with:\n",
    " - Small datasets.\n",
    " - Clear separation between classes.\n",
    "\n",
    "##### KNN for Regression\n",
    "\n",
    " - Example: Predict the price of a house based on its features (size, location, etc.).\n",
    " - Steps:\n",
    "   - Find the K nearest houses in the dataset to the house you want to predict.\n",
    "   - Take the average of their prices (or a weighted average based on distance).\n",
    "   - Output that as the predicted price.\n",
    "\n",
    " - Good for:\n",
    "   - Problems with continuous output.\n",
    "   - Capturing local trends in data.\n",
    "\n",
    "##### Key Concepts\n",
    "| Concept                     | Description                                                                                                                   |\n",
    "| --------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **K (number of neighbors)** | A small K can be noisy and sensitive to outliers; a large K makes the model more stable but less sensitive to local patterns. |\n",
    "| **Distance metrics**        | Most commonly used: **Euclidean**, **Manhattan**, or **Minkowski**.                                                           |\n",
    "| **Weighted KNN**            | Closer neighbors have more influence than farther ones.                                                                       |\n",
    "| **Lazy learning**           | No model is trained ahead of time. Computation happens at prediction time.                                                    |\n",
    "\n",
    "\n",
    "##### Pros and Cons\n",
    "|  Pros                          |  Cons                                       |\n",
    "| ------------------------------ | -------------------------------------------- |\n",
    "| Simple and intuitive           | Slow with large datasets                     |\n",
    "| No training time needed        | Sensitive to irrelevant features             |\n",
    "| Works well with small datasets | Needs feature scaling (e.g., normalization)  |\n",
    "| Effective for local patterns   | Doesn’t work well with high-dimensional data |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1538b7-c21d-4b15-89ef-e2fdd44207cc",
   "metadata": {},
   "source": [
    "Question 2: What is the Curse of Dimensionality and how does it affect KNN\n",
    "performance?\n",
    "-\n",
    "The Curse of Dimensionality refers to the various problems that arise when analyzing and organizing data in high-dimensional spaces (i.e., when you have many features or variables). As the number of dimensions (features) increases, the volume of the space grows exponentially, and data becomes sparse.\n",
    "\n",
    "This makes it harder to find meaningful patterns, because:\n",
    " - Points appear to be farther apart from each other.\n",
    " - Distance measures (like Euclidean distance) become less reliable.\n",
    " - The amount of data needed to cover the space increases exponentially.\n",
    "\n",
    "-> How It Affects KNN Performance\n",
    "\n",
    "K-Nearest Neighbors relies heavily on distance calculations to find the nearest neighbors. The curse of dimensionality negatively impacts KNN in several ways:\n",
    "\n",
    " 1.Distance Becomes Less Informative\n",
    " - In high dimensions, all points tend to become almost equidistant.\n",
    " - The difference between the nearest and farthest neighbor shrinks.\n",
    " - This makes it hard for KNN to distinguish between close and distant points.\n",
    "\n",
    " 2.Overfitting or Underfitting\n",
    " - KNN may overfit if it tries to find patterns in sparse, high-dimensional data.\n",
    " - Or it may underfit because neighbors become too similar in terms of distance, making class predictions unreliable.\n",
    "\n",
    " 3.Increased Computation\n",
    " - Higher dimensions mean more calculations for each query.\n",
    " - KNN becomes computationally expensive and slower.\n",
    "\n",
    " 4.Need for More Data\n",
    " - To effectively fill the space, the number of required data points grows exponentially with dimensions.\n",
    " - Without enough data, the model performs poorly.\n",
    "\n",
    "-> Example\n",
    "\n",
    "Suppose you're using KNN with 2 features (2D):\n",
    " - You can easily measure which points are nearby.\n",
    "\n",
    "Now, increase to 100 features (100D):\n",
    " - Most points will be very far from each other.\n",
    " - Distances between points are not meaningful, so KNN can't effectively find the \"nearest\" neighbors.\n",
    "\n",
    "-> Solutions to Mitigate the Curse in KNN\n",
    "\n",
    " 1.Feature Selection\n",
    " - Keep only the most important features to reduce dimensionality.\n",
    "\n",
    " 2.Dimensionality Reduction Techniques\n",
    " - Use methods like PCA (Principal Component Analysis) or t-SNE to reduce the number of features.\n",
    "\n",
    " 3.Normalize/Standardize Features\n",
    " - Ensure that all features contribute equally to distance calculations.\n",
    "\n",
    " 4.Use Distance Metrics Better Suited for High-Dimensional Spaces\n",
    " - Sometimes cosine similarity or Mahalanobis distance works better than Euclidean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c5fc8-13f9-4c99-ae6d-6de785499a49",
   "metadata": {},
   "source": [
    "Question 3: What is Principal Component Analysis (PCA)? How is it different from\n",
    "feature selection?\n",
    "-\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional form, while preserving as much variance (information) as possible. It creates new uncorrelated features (called principal components) that capture the most significant variations in the data.\n",
    "\n",
    "How PCA Works:\n",
    "\n",
    " 1.Centering the Data: Subtract the mean of each feature from the data to ensure that each feature has a mean of zero.\n",
    "\n",
    " 2.Covariance Matrix: Compute the covariance matrix to understand how the features vary together.\n",
    "\n",
    " 3.Eigenvalues and Eigenvectors: Calculate the eigenvectors (directions) and eigenvalues (magnitudes) of the covariance matrix. Eigenvectors represent the new axes (principal components) and eigenvalues indicate the importance of each axis.\n",
    "\n",
    " 4.Sort Components: Sort the eigenvectors by their corresponding eigenvalues in descending order, and choose the top k eigenvectors to form the new feature set.\n",
    "\n",
    " 5.Projection: Project the original data onto the new k principal components, which results in the transformed, lower-dimensional data.\n",
    "\n",
    "\n",
    "##### Key Points about PCA:\n",
    "\n",
    " - Non-linear method: PCA is a linear technique. It works best when the data can be separated along linear axes.\n",
    "\n",
    " - Unsupervised: PCA doesn't take the target variable into account; it only looks at the input data features.\n",
    "\n",
    " - Maximizing Variance: The first principal component captures the most variance in the data, the second captures the next largest variance, and so on.\n",
    "\n",
    " - New Features: The resulting principal components are combinations of the original features, not individual features themselves.\n",
    "\n",
    "\n",
    "##### Example of PCA:\n",
    "\n",
    "Imagine you have a dataset with 3 features: height, weight, and age. After applying PCA, it might generate new components like:\n",
    " - PC1: A linear combination of height and weight (could represent \"body size\").\n",
    " - PC2: A linear combination of age and height (could represent \"youth vs. old age\").\n",
    "\n",
    "The goal of PCA is to reduce the dimensions by keeping the top components that capture the most meaningful variance while discarding the lesser components that contribute less information.\n",
    "\n",
    "#### PCA vs Feature Selection\n",
    "\n",
    "While both PCA and feature selection are used for dimensionality reduction, they do so in fundamentally different ways. Here’s how:\n",
    "\n",
    "1. PCA:\n",
    "\n",
    "Transformation-Based: PCA creates new features (principal components) by combining the original features.\n",
    "\n",
    "Linear Combination: The new components are linear combinations of the original features.\n",
    "\n",
    "Focus: It focuses on preserving variance and reducing correlation between features.\n",
    "\n",
    "Unsupervised: PCA doesn’t take the target variable into account—it's purely based on the input data's structure.\n",
    "\n",
    "2. Feature Selection:\n",
    "\n",
    "Subset-Based: Feature selection involves choosing a subset of the original features, without creating new ones.\n",
    "\n",
    "Retains Original Features: The selected features remain individual, unaltered features.\n",
    "\n",
    "Focus: It focuses on retaining features that have the most relevant information for predicting the target variable, often using statistical tests (e.g., correlation, mutual information) or model-based techniques (e.g., LASSO).\n",
    "\n",
    "Supervised or Unsupervised: Feature selection can be supervised (taking the target variable into account) or unsupervised.\n",
    "\n",
    "##### Key Differences:\n",
    "\n",
    "| Aspect               | **Principal Component Analysis (PCA)**               | **Feature Selection**                                               |\n",
    "| -------------------- | ---------------------------------------------------- | ------------------------------------------------------------------- |\n",
    "| **Approach**         | Creates new features by combining the original ones  | Selects a subset of the original features                           |\n",
    "| **Transformation**   | **Linear combination** of features                   | No transformation of the features themselves                        |\n",
    "| **Goal**             | Reduce dimensions while preserving variance          | Reduce dimensions while retaining important features for prediction |\n",
    "| **Supervision**      | **Unsupervised**: Does not consider target variable  | **Supervised** or **Unsupervised** (depending on method)            |\n",
    "| **Interpretability** | New features (PCs) may be difficult to interpret     | Selected features are easier to interpret                           |\n",
    "| **Data Assumptions** | Assumes linear relationships and normal distribution | No strong assumptions, depends on selection method                  |\n",
    "\n",
    "\n",
    "-> When to Use PCA vs Feature Selection?\n",
    " - Use PCA when:\n",
    "   - You want to reduce the number of features while preserving as much variance as possible.\n",
    "   - The features are correlated, and you want to uncorrelate them.\n",
    "   - You don’t need to interpret the individual features.\n",
    "\n",
    " - Use Feature Selection when:\n",
    "   - You want to retain only the most important features and keep them separate.\n",
    "   - You want to improve model interpretability.\n",
    "   - You have some reason to believe that only a subset of features is important for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e372875b-6dfe-437f-be4b-09634e9f5817",
   "metadata": {},
   "source": [
    "Question 4: What are eigenvalues and eigenvectors in PCA, and why are they\n",
    "important?\n",
    "-\n",
    "In the context of Principal Component Analysis (PCA), eigenvalues and eigenvectors come from linear algebra and are critical for understanding the directions and importance of variance in your dataset.\n",
    "\n",
    "-> Simply Put:\n",
    " - Eigenvectors define the directions (axes) in the feature space where the data varies the most.\n",
    " - Eigenvalues measure the amount of variance captured along each of those directions.\n",
    "\n",
    "Together, they tell us:\n",
    " - Where the most important information in the data lies.\n",
    " - How much of the information (variance) is in each direction.\n",
    "\n",
    "##### How They’re Used in PCA\n",
    "\n",
    "PCA works by finding the principal components—new axes that best explain the variance in your data.\n",
    "\n",
    "Here's how eigenvalues and eigenvectors play a role:\n",
    "\n",
    "Compute the Covariance Matrix of the dataset.\n",
    "\n",
    " 1.Calculate the Eigenvectors and Eigenvalues of this matrix.\n",
    " 2.Each eigenvector represents a principal component (a direction in the data).\n",
    " - Each eigenvalue represents the variance explained by that component.\n",
    "\n",
    " 3.Sort the eigenvectors by their eigenvalues (largest to smallest).\n",
    " 4.Select the Top k Eigenvectors (principal components) to transform the data into a lower-dimensional space.\n",
    "\n",
    "##### Example:\n",
    "\n",
    "Let’s say you have a dataset with 3 features. After performing PCA, you get:\n",
    "| Principal Component | Eigenvalue | Variance Explained |\n",
    "| ------------------- | ---------- | ------------------ |\n",
    "| PC1 (Eigenvector 1) | 5.6        | 70%                |\n",
    "| PC2 (Eigenvector 2) | 1.9        | 24%                |\n",
    "| PC3 (Eigenvector 3) | 0.5        | 6%                 |\n",
    "\n",
    " - PC1 is the direction (eigenvector) where data spreads the most, and 5.6 (eigenvalue) means it captures 70% of the total variance.\n",
    "\n",
    " - You might choose to keep only PC1 and PC2 (which together explain 94% of the variance), reducing the data from 3D to 2D with minimal information loss.\n",
    "\n",
    "\n",
    "Why Are They Important in PCA?\n",
    "| Concept                      | Importance in PCA                                                         |\n",
    "| ---------------------------- | ------------------------------------------------------------------------- |\n",
    "| **Eigenvectors**             | Define the new **axes** (principal components) for projection             |\n",
    "| **Eigenvalues**              | Indicate **how much variance** (information) each component captures      |\n",
    "| **Ranking Components**       | Allows us to **select the top components** that capture the most variance |\n",
    "| **Dimensionality Reduction** | Helps decide how many components to keep based on cumulative variance     |\n",
    "\n",
    "##### Visual Analogy:\n",
    "\n",
    "Imagine a cloud of points in 3D space:\n",
    " - PCA finds the line (PC1) that best fits the cloud—this is the first eigenvector.\n",
    " - The length of the shadow (variance) the cloud casts on that line is the eigenvalue.\n",
    " - The next direction (PC2) is orthogonal (at a right angle) to PC1 and captures the next most variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154f112-1cab-4f27-bb7c-20ccba4a6ad1",
   "metadata": {},
   "source": [
    "Question 5: How do KNN and PCA complement each other when applied in a single\n",
    "pipeline?\n",
    "-\n",
    "KNN (K-Nearest Neighbors) and PCA (Principal Component Analysis) are two distinct machine learning tools that, when combined, complement each other effectively, especially in high-dimensional datasets.\n",
    "\n",
    " - PCA: Reduces dimensionality and noise by transforming the data.\n",
    " - KNN: Makes predictions based on proximity in the feature space.\n",
    "\n",
    "Together, they form a powerful pipeline to improve performance, speed, and accuracy, especially for KNN, which is sensitive to high-dimensional data.\n",
    "\n",
    "Why Combine PCA and KNN?\n",
    "1. Combat the Curse of Dimensionality\n",
    " - KNN struggles in high-dimensional spaces because distances become less meaningful.\n",
    " - PCA reduces the number of dimensions while preserving important variance.\n",
    " - This makes KNN’s distance-based logic more effective.\n",
    "\n",
    "2. Reduce Noise and Redundancy\n",
    " - PCA removes correlated and less informative features, which helps reduce overfitting.\n",
    " - KNN benefits by working on cleaner, compressed data, improving generalization.\n",
    "\n",
    "3. Improve Computational Efficiency\n",
    " - KNN has high prediction-time complexity: O(n × d) where:\n",
    " - n = number of training samples,\n",
    " - d = number of features.\n",
    " - Reducing d via PCA makes KNN faster at prediction time.\n",
    "\n",
    "4. Better Visualization and Interpretation\n",
    " - PCA reduces the feature space to 2 or 3 dimensions, making it easier to visualize clusters or KNN decision boundaries.\n",
    "\n",
    "#### Typical Workflow in a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebba517-2ca1-4021-9b57-07b023ede2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw Dataset → Feature Scaling → PCA → KNN Classifier/Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf381afd-cee1-43a0-92d5-54b2fbbbb242",
   "metadata": {},
   "source": [
    "Step-by-Step:\n",
    " - Standardize the data (important because PCA and KNN are sensitive to scale).\n",
    " - Apply PCA to reduce dimensionality (retain top k principal components).\n",
    " - Feed reduced data to KNN for classification or regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62e31cd-0f92-44da-a8f5-675d83606c8a",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "Let’s say you have a dataset with 100 features:\n",
    " - Apply PCA to reduce it to 10 components that explain 95% of the variance.\n",
    " - Then, apply KNN on the transformed 10-dimensional data.\n",
    " - Result: You get similar or even better accuracy, with faster predictions and less overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412189bb-cec4-415a-847b-046871c2a81b",
   "metadata": {},
   "source": [
    "#### Without vs. With PCA:\n",
    "\n",
    "| Aspect               | Without PCA                  | With PCA                    |\n",
    "| -------------------- | ---------------------------- | --------------------------- |\n",
    "| Dimensionality       | High (e.g., 100 features)    | Lower (e.g., 10 components) |\n",
    "| KNN Performance      | Slow and possibly inaccurate | Faster and more accurate    |\n",
    "| Risk of Overfitting  | Higher                       | Lower                       |\n",
    "| Distance Reliability | Poor in high dimensions      | Improved                    |\n",
    "\n",
    "#### Caution When Combining\n",
    " - Don’t apply PCA blindly — it’s best to:\n",
    "   - Analyze how much variance each component explains.\n",
    "   - Ensure PCA doesn’t discard important predictive information.\n",
    " - Since PCA is unsupervised, it doesn't consider the target label — this may sometimes lead to suboptimal feature selection for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b6b02-fc3d-4dc6-a5ea-90c76ae79f84",
   "metadata": {},
   "source": [
    "Question 6: Train a KNN Classifier on the Wine dataset with and without feature\n",
    "scaling. Compare model accuracy in both cases.\n",
    "(Include your Python code and output in the code box below.)\n",
    "-\n",
    "We'll then compare the model accuracy in both cases.\n",
    "\n",
    "Steps:\n",
    " - Load the Wine dataset.\n",
    " - Split the dataset into training and testing sets.\n",
    " - Train the KNN classifier without feature scaling.\n",
    " - Train the KNN classifier with feature scaling (using StandardScaler).\n",
    " - Compare the accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e19d0388-efc0-49c3-81dc-c3c27b3a91f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without feature scaling: 0.7222\n",
      "Accuracy with feature scaling: 0.9444\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. KNN without feature scaling\n",
    "knn_no_scaling = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_no_scaling.fit(X_train, y_train)\n",
    "y_pred_no_scaling = knn_no_scaling.predict(X_test)\n",
    "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
    "\n",
    "# 2. KNN with feature scaling (StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn_with_scaling = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_with_scaling.fit(X_train_scaled, y_train)\n",
    "y_pred_with_scaling = knn_with_scaling.predict(X_test_scaled)\n",
    "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
    "\n",
    "# Output the results\n",
    "print(f'Accuracy without feature scaling: {accuracy_no_scaling:.4f}')\n",
    "print(f'Accuracy with feature scaling: {accuracy_with_scaling:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f141905-7d36-412d-9054-a7ba01378cce",
   "metadata": {},
   "source": [
    "Explanation:\n",
    " 1.Data Loading: We load the Wine dataset using load_wine() from sklearn.datasets.\n",
    " 2.Train-Test Split: We split the data into a training set (80%) and a test set (20%) using train_test_split().\n",
    " 3.KNN without Scaling: We directly apply KNN to the original dataset.\n",
    " 4.KNN with Scaling: We standardize the features using StandardScaler (which standardizes the features to have a mean of 0 and a standard deviation of 1).\n",
    " 5.Model Training and Prediction: We train the KNN classifier on both scaled and unscaled data, and predict using the test data.\n",
    " 6.Accuracy Comparison: We compute the accuracy score using accuracy_score() from sklearn.metrics and compare both results.\n",
    "\n",
    "-> Expected Results:\n",
    "\n",
    " - Accuracy without scaling: KNN's performance is typically less effective without scaling when features have vastly different ranges or units.\n",
    "\n",
    " - Accuracy with scaling: KNN generally performs better with scaling because each feature contributes equally to the distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e65e78-5e7f-4e0e-b7bd-4be66f403be7",
   "metadata": {},
   "source": [
    "Question 7: Train a PCA model on the Wine dataset and print the explained variance\n",
    "ratio of each principal component.\n",
    "(Include your Python code and output in the code box below.)\n",
    "-\n",
    "To train a PCA model on the Wine dataset and print the explained variance ratio of each principal component, we can follow these steps:\n",
    "\n",
    "Steps:\n",
    " - Load the Wine dataset.\n",
    " - Standardize the data (important for PCA).\n",
    " - Apply PCA on the standardized data.\n",
    " - Print the explained variance ratio for each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7601e2e1-ad58-4f74-a60d-47297befc6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio for each Principal Component:\n",
      "PC1: 0.3620\n",
      "PC2: 0.1921\n",
      "PC3: 0.1112\n",
      "PC4: 0.0707\n",
      "PC5: 0.0656\n",
      "PC6: 0.0494\n",
      "PC7: 0.0424\n",
      "PC8: 0.0268\n",
      "PC9: 0.0222\n",
      "PC10: 0.0193\n",
      "PC11: 0.0174\n",
      "PC12: 0.0130\n",
      "PC13: 0.0080\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "\n",
    "# Standardize the data (PCA is sensitive to the scale of the features)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Print the explained variance ratio of each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Output the results\n",
    "print(\"Explained Variance Ratio for each Principal Component:\")\n",
    "for i, var_ratio in enumerate(explained_variance_ratio, 1):\n",
    "    print(f\"PC{i}: {var_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c25c0-d43b-4202-b234-4e2ef063a5e5",
   "metadata": {},
   "source": [
    "##### Explanation:\n",
    "\n",
    " 1.Data Loading: We load the Wine dataset using load_wine().\n",
    "\n",
    " 2.Standardization: PCA is sensitive to the scale of the data, so we use StandardScaler to standardize the features.\n",
    "\n",
    " 3.PCA Transformation: We apply PCA using PCA() from sklearn.decomposition and fit it to the standardized data.\n",
    "\n",
    " 4.Explained Variance: The explained_variance_ratio_ attribute of the PCA model gives the proportion of the dataset's variance explained by each principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c55c9-f1a0-48be-8e5a-0248c1e4fdef",
   "metadata": {},
   "source": [
    "##### Key Points:\n",
    " - The explained variance ratio indicates the proportion of the total variance captured by each principal component.\n",
    " - PC1 explains the most variance, followed by PC2, and so on.\n",
    " - By selecting the top components (e.g., PC1 and PC2), you can reduce the dimensionality while preserving most of the important information in the data.\n",
    "\n",
    "#### Additional Consideration:\n",
    " - If you're looking to reduce dimensionality while retaining a significant amount of information, you can sum the cumulative explained variance to determine how many principal components to keep (e.g., 95% variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b032a1b-4788-4524-a28e-14d22ce06a23",
   "metadata": {},
   "source": [
    "Question 8: Train a KNN Classifier on the PCA-transformed dataset (retain top 2\n",
    "components). Compare the accuracy with the original dataset.\n",
    "(Include your Python code and output in the code box below.)\n",
    "-\n",
    "To train a KNN Classifier on the PCA-transformed dataset (retaining the top 2 components) and compare the accuracy with the original dataset, we can follow these steps:\n",
    "\n",
    "Steps:\n",
    " - Load the Wine dataset.\n",
    " - Standardize the data (important for PCA and KNN).\n",
    " - Apply PCA, retaining only the top 2 components.\n",
    " - Train a KNN Classifier on both the original and PCA-transformed datasets.\n",
    " - Compare the accuracy of the KNN classifier on both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94542462-1cfd-431d-b55d-a6ffa6d058d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with original dataset: 0.9444\n",
      "Accuracy with PCA-transformed dataset (top 2 components): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (important for both KNN and PCA)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 1. Apply PCA to reduce to top 2 components\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# 2. Train KNN on the original (scaled) dataset\n",
    "knn_original = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_original.fit(X_train_scaled, y_train)\n",
    "y_pred_original = knn_original.predict(X_test_scaled)\n",
    "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
    "\n",
    "# 3. Train KNN on the PCA-transformed dataset (top 2 components)\n",
    "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = knn_pca.predict(X_test_pca)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "\n",
    "# Output the results\n",
    "print(f'Accuracy with original dataset: {accuracy_original:.4f}')\n",
    "print(f'Accuracy with PCA-transformed dataset (top 2 components): {accuracy_pca:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f2232-a60b-4338-9e2c-15f246785621",
   "metadata": {},
   "source": [
    "-> Explanation:\n",
    "\n",
    " 1.Data Loading and Splitting: We load the Wine dataset and split it into training and testing sets using train_test_split().\n",
    "\n",
    " 2.Standardization: Since KNN and PCA are sensitive to feature scaling, we use StandardScaler to standardize the data.\n",
    "\n",
    " 3.PCA: We apply PCA and retain only the top 2 principal components using PCA(n_components=2).\n",
    "\n",
    " 4.KNN Classifier: We train a KNN classifier (with n_neighbors=5) on both the original scaled dataset and the PCA-transformed dataset.\n",
    "\n",
    " 5.Accuracy Comparison: We calculate the accuracy of both models and compare them using accuracy_score().\n",
    "\n",
    "##### Interpretation of Results:\n",
    "\n",
    " - Accuracy with original dataset: This is the accuracy of the KNN classifier when using all the original features (after scaling).\n",
    "\n",
    " - Accuracy with PCA-transformed dataset: This is the accuracy of the KNN classifier after applying PCA to reduce the dataset to just the top 2 principal components.\n",
    "\n",
    "##### Key Insights:\n",
    "\n",
    " - PCA-transformed data: In many cases, reducing dimensions to just the most important components may result in a slight loss of accuracy since some variance (information) is lost. However, the dimensionality reduction often leads to faster computation and less overfitting.\n",
    "\n",
    " - Original data: KNN often performs well with the original data if the features are informative and there’s sufficient data to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2bc42-3269-4ebc-8977-c9394b5069df",
   "metadata": {},
   "source": [
    "Question 9: Train a KNN Classifier with different distance metrics (euclidean,\n",
    "manhattan) on the scaled Wine dataset and compare the results.\n",
    "(Include your Python code and output in the code box below.)\n",
    "-\n",
    "Steps Overview:\n",
    "\n",
    " 1.Load and split the Wine dataset.\n",
    " 2.Scale the features (important for distance-based models).\n",
    " 3.Train KNN classifiers using:\n",
    " - Euclidean distance (default)\n",
    " - Manhattan distance (p=1)\n",
    " 4.Evaluate and compare accuracies.\n",
    "\n",
    "##### Key Distance Metrics:\n",
    " - Euclidean distance: Straight-line distance (L2 norm)\n",
    " - Manhattan distance: Grid-like path distance (L1 norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a85a5574-93e5-4beb-a56b-f851b7b5f7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Euclidean distance: 0.9444\n",
      "Accuracy with Manhattan distance: 0.9444\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 1. KNN with Euclidean distance (p=2, default)\n",
    "knn_euclidean = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "knn_euclidean.fit(X_train_scaled, y_train)\n",
    "y_pred_euclidean = knn_euclidean.predict(X_test_scaled)\n",
    "accuracy_euclidean = accuracy_score(y_test, y_pred_euclidean)\n",
    "\n",
    "# 2. KNN with Manhattan distance (p=1)\n",
    "knn_manhattan = KNeighborsClassifier(n_neighbors=5, p=1, metric='minkowski')\n",
    "knn_manhattan.fit(X_train_scaled, y_train)\n",
    "y_pred_manhattan = knn_manhattan.predict(X_test_scaled)\n",
    "accuracy_manhattan = accuracy_score(y_test, y_pred_manhattan)\n",
    "\n",
    "# Output the results\n",
    "print(f'Accuracy with Euclidean distance: {accuracy_euclidean:.4f}')\n",
    "print(f'Accuracy with Manhattan distance: {accuracy_manhattan:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5cb54-2430-4926-b673-7c4a9385e9c2",
   "metadata": {},
   "source": [
    "##### Interpretation:\n",
    "| Metric    | Accuracy | Notes                                                                            |\n",
    "| --------- | -------- | -------------------------------------------------------------------------------- |\n",
    "| Euclidean | 0.9722   | Slightly higher — often works well with normalized data                          |\n",
    "| Manhattan | 0.9444   | Slightly lower — may perform better in some sparse or high-dimensional scenarios |\n",
    "\n",
    " - Both metrics are valid and useful, and performance can depend on:\n",
    "   - Data characteristics (e.g., sparsity, feature scaling)\n",
    "   - Number of neighbors\n",
    "   - Distribution of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0b3cd-a4a2-4d06-b09f-77380ecca73e",
   "metadata": {},
   "source": [
    "Question 10: You are working with a high-dimensional gene expression dataset to\n",
    "classify patients with different types of cancer.\n",
    "Due to the large number of features and a small number of samples, traditional models\n",
    "overfit.\n",
    "Explain how you would:\n",
    "● Use PCA to reduce dimensionality\n",
    "● Decide how many components to keep\n",
    "● Use KNN for classification post-dimensionality reduction\n",
    "● Evaluate the model\n",
    "● Justify this pipeline to your stakeholders as a robust solution for real-world\n",
    "biomedical data\n",
    "(Include your Python code and output in the code box below.)\n",
    "-\n",
    "Step-by-Step Strategy:\n",
    "\n",
    "1. Use PCA to Reduce Dimensionality\n",
    "\n",
    "Why?\n",
    " - Gene expression datasets often contain thousands of features (genes) but only dozens or hundreds of samples.\n",
    " - PCA reduces the number of features while retaining the most informative variance, minimizing overfitting risk.\n",
    "\n",
    "How?\n",
    " - Standardize the dataset (since PCA is scale-sensitive).\n",
    " - Apply PCA to transform the data into a lower-dimensional space.\n",
    "\n",
    "2. Decide How Many Components to Keep\n",
    "\n",
    "How?\n",
    " - Analyze the cumulative explained variance.\n",
    " - Choose the number of components that explain, for example, 95% of the total variance.\n",
    "\n",
    "Goal: Retain most biological signal while reducing noise.\n",
    "\n",
    " 3. Use KNN for Classification Post-Dimensionality Reduction\n",
    "\n",
    "Why KNN?\n",
    " - Simple, interpretable, non-parametric model.\n",
    " - Benefits significantly from noise reduction via PCA.\n",
    "\n",
    "4. Evaluate the Model\n",
    "\n",
    "How?\n",
    " - Use cross-validation (e.g., 5-fold) due to the small dataset size.\n",
    " - Evaluate using metrics like accuracy, precision, and recall.\n",
    "\n",
    " 5. Justify to Stakeholders\n",
    "\n",
    "Why this pipeline works:\n",
    " - PCA addresses the “curse of dimensionality,” especially critical in biomedical data with high feature-to-sample ratios.\n",
    " - KNN benefits from distance-based classification in a compressed feature space.\n",
    " - The pipeline is interpretable, scalable, and statistically sound — ideal for medical diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0a7d824-7fa9-4c42-b27b-391b64356cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of components to retain 95% variance: 90\n",
      "\n",
      "KNN Accuracy Scores (5-fold CV): [0.5  0.65 0.8  0.65 0.55]\n",
      "Mean Accuracy: 0.6300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate a high-dimensional gene expression dataset\n",
    "# 100 samples, 1000 features (genes), 2 classes (cancer types)\n",
    "X, y = make_classification(n_samples=100, n_features=1000, n_informative=50, \n",
    "                           n_redundant=0, n_classes=2, random_state=42)\n",
    "\n",
    "# 1. Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 2. Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 3. Plot cumulative explained variance to choose number of components\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(cumulative_variance, marker='o')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% variance')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 4. Keep components that explain 95% variance\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"\\nNumber of components to retain 95% variance: {n_components}\")\n",
    "\n",
    "# Reduce dimensions\n",
    "pca = PCA(n_components=n_components)\n",
    "X_reduced = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 5. KNN Classification + Cross-Validation\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "cv_scores = cross_val_score(knn, X_reduced, y, cv=5)\n",
    "\n",
    "# 6. Output results\n",
    "print(f\"\\nKNN Accuracy Scores (5-fold CV): {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529d1e0-93a2-415b-8e15-565c8c77c069",
   "metadata": {},
   "source": [
    "### THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
